{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13088,"status":"ok","timestamp":1653575349648,"user":{"displayName":"Bruce HU","userId":"02309357718155453395"},"user_tz":-120},"id":"ce2T9IjtxS2O","outputId":"f0b26dbe-f056-4813-a01c-b3ff91ca9a3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8956,"status":"ok","timestamp":1653575331726,"user":{"displayName":"Bruce HU","userId":"02309357718155453395"},"user_tz":-120},"id":"vZwq84Xtc1JK","outputId":"d2943fa2-f1ec-4831-9fd5-b4f100fd8f22"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 4.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 49.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 61.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11065,"status":"ok","timestamp":1653575437457,"user":{"displayName":"Bruce HU","userId":"02309357718155453395"},"user_tz":-120},"id":"X_LoSSX_xLDc","outputId":"ac5bb5a9-6ee8-4f57-b3b9-38bd2908cffd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Process drive/MyDrive/CocaKE_ver3.5/data/FB15k237/train.txt...\n","Load 14904 entity descriptions from drive/MyDrive/CocaKE_ver3.5/data/FB15k237/FB15k_mid2description.txt\n","No desc found for /m/02vxfw_\n","No desc found for /m/02jxk\n","No desc found for /m/03m3nzf\n","No desc found for /m/04_1l0v\n","No desc found for /m/09x_r\n","No desc found for /m/0bytsc\n","No desc found for /m/07_bv_\n","No desc found for /m/03lsz8h\n","No desc found for /m/05xf75\n","No desc found for /m/01dy7j\n","No desc found for /m/09ly2r6\n","No desc found for /m/015zql\n","No desc found for /m/047vp20\n","No desc found for /m/0hk18\n","No desc found for /m/061zc_\n","No desc found for /m/0cfywh\n","No desc found for /m/03tp4\n","No desc found for /m/029cpw\n","No desc found for /m/0lmb5\n","No desc found for /m/0m6x4\n","No desc found for /m/09l65\n","No desc found for /m/0147fv\n","No desc found for /m/0kvrb\n","No desc found for /m/03gwg4w\n","No desc found for /m/0bm39zf\n","No desc found for /m/08mbj32\n","No desc found for /m/068bs\n","No desc found for /m/01xzb6\n","No desc found for /m/07djnx\n","No desc found for /m/02q_plc\n","No desc found for /m/02cjrp\n","No desc found for /m/01xsbh\n","No desc found for /m/03bx017\n","No desc found for /m/01sy5c\n","No desc found for /m/0854hr\n","No desc found for /m/0h005\n","No desc found for /m/01fkv0\n","No desc found for /m/05h4fjx\n","No desc found for /m/05ry0p\n","No desc found for /m/01dvms\n","No desc found for /m/04686_j\n","No desc found for /m/08chdb\n","No desc found for /m/05zvq6g\n","No desc found for /m/0288crq\n","No desc found for /m/01my929\n","No desc found for /m/07t_l23\n","No desc found for /m/07s4911\n","Load 14951 entity names from drive/MyDrive/CocaKE_ver3.5/data/FB15k237/FB15k_mid2name.txt\n","Save 237 relations to drive/MyDrive/CocaKE_ver3.5/data/FB15k237/relations.json\n","Save 272115 examples to drive/MyDrive/CocaKE_ver3.5/data/FB15k237/train.txt.json\n","Process drive/MyDrive/CocaKE_ver3.5/data/FB15k237/valid.txt...\n","Save 17535 examples to drive/MyDrive/CocaKE_ver3.5/data/FB15k237/valid.txt.json\n","Process drive/MyDrive/CocaKE_ver3.5/data/FB15k237/test.txt...\n","Save 20466 examples to drive/MyDrive/CocaKE_ver3.5/data/FB15k237/test.txt.json\n","Get 14541 entities, 237 relations in total\n","Done\n"]}],"source":["!python -u preprocess.py --task \"FB15k237\" \\\n","--train-path \"data/FB15k237/train.txt\" \\\n","--valid-path \"data/FB15k237/valid.txt\" \\\n","--test-path \"data/FB15k237/test.txt\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsHAPIyscjw_","outputId":"e1389849-b7ef-4bb4-fde6-593c07509022"},"outputs":[{"name":"stderr","output_type":"stream","text":["e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3.5\\main.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n","  import imp\n","[2022-05-26 18:40:07,705 INFO] Load 14541 entities from data/FB15k237\\entities.json\n","[2022-05-26 18:40:07,705 INFO] Triplets path: ['data/FB15k237/train.txt.json']\n","[2022-05-26 18:40:09,782 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-26 18:40:09,784 INFO] Start to build link graph from data/FB15k237/train.txt.json\n","[2022-05-26 18:40:10,738 INFO] Done build link graph with 14505 nodes\n","2022-05-26 18:40:13.070684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-26 18:40:13.071002: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-26 18:40:18,171 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-26 18:40:18,171 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-26 18:40:19,141 INFO] Use 1 gpus for training\n","[2022-05-26 18:40:22,836 INFO] Build tokenizer from bert-base-uncased\n","[2022-05-26 18:40:22,837 INFO] => creating model\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-05-26 18:40:25,734 INFO] CustomBertModel(\n","  (hr_bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (tail_bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n",")\n","e:\\Anaconda\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","[2022-05-26 18:40:29,300 INFO] log_inv_t: 1.0\n","[2022-05-26 18:40:29,301 INFO] hr_bert.embeddings.word_embeddings.weight: 23440896\n","[2022-05-26 18:40:29,301 INFO] hr_bert.embeddings.position_embeddings.weight: 393216\n","[2022-05-26 18:40:29,301 INFO] hr_bert.embeddings.token_type_embeddings.weight: 1536\n","[2022-05-26 18:40:29,301 INFO] hr_bert.embeddings.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,301 INFO] hr_bert.embeddings.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,301 INFO] hr_bert.encoder.layer.0.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,301 INFO] hr_bert.encoder.layer.0.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,301 INFO] hr_bert.encoder.layer.0.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,301 INFO] hr_bert.encoder.layer.0.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,301 INFO] hr_bert.encoder.layer.0.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,301 INFO] hr_bert.encoder.layer.0.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.output.dense.bias: 768\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.0.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.1.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,302 INFO] hr_bert.encoder.layer.1.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.output.dense.bias: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.1.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,303 INFO] hr_bert.encoder.layer.2.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.output.dense.bias: 768\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,304 INFO] hr_bert.encoder.layer.2.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,305 INFO] hr_bert.encoder.layer.3.output.dense.bias: 768\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.3.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.3.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.4.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.4.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.4.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.4.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.4.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.4.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,306 INFO] hr_bert.encoder.layer.4.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.output.dense.bias: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.4.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.5.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.5.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.5.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.5.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.5.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.5.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,307 INFO] hr_bert.encoder.layer.5.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.output.dense.bias: 768\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.5.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.6.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.6.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.6.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.6.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,308 INFO] hr_bert.encoder.layer.6.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.output.dense.bias: 768\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.6.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.7.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.7.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,309 INFO] hr_bert.encoder.layer.7.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.output.dense.bias: 768\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.7.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.8.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,310 INFO] hr_bert.encoder.layer.8.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.output.dense.bias: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.8.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,311 INFO] hr_bert.encoder.layer.9.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.output.dense.bias: 768\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,312 INFO] hr_bert.encoder.layer.9.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,313 INFO] hr_bert.encoder.layer.10.output.dense.bias: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.10.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.10.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,314 INFO] hr_bert.encoder.layer.11.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,315 INFO] hr_bert.encoder.layer.11.output.dense.bias: 768\n","[2022-05-26 18:40:29,315 INFO] hr_bert.encoder.layer.11.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,315 INFO] hr_bert.encoder.layer.11.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,315 INFO] hr_bert.pooler.dense.weight: 589824\n","[2022-05-26 18:40:29,315 INFO] hr_bert.pooler.dense.bias: 768\n","[2022-05-26 18:40:29,315 INFO] tail_bert.embeddings.word_embeddings.weight: 23440896\n","[2022-05-26 18:40:29,315 INFO] tail_bert.embeddings.position_embeddings.weight: 393216\n","[2022-05-26 18:40:29,315 INFO] tail_bert.embeddings.token_type_embeddings.weight: 1536\n","[2022-05-26 18:40:29,315 INFO] tail_bert.embeddings.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,315 INFO] tail_bert.embeddings.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,315 INFO] tail_bert.encoder.layer.0.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,315 INFO] tail_bert.encoder.layer.0.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,315 INFO] tail_bert.encoder.layer.0.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,315 INFO] tail_bert.encoder.layer.0.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,315 INFO] tail_bert.encoder.layer.0.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.output.dense.bias: 768\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.0.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.1.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.1.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,316 INFO] tail_bert.encoder.layer.1.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.output.dense.bias: 768\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.1.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.2.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,317 INFO] tail_bert.encoder.layer.2.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.output.dense.bias: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.2.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.3.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,318 INFO] tail_bert.encoder.layer.3.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.output.dense.bias: 768\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,319 INFO] tail_bert.encoder.layer.3.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.output.dense.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.4.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.5.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.5.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.5.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,320 INFO] tail_bert.encoder.layer.5.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,321 INFO] tail_bert.encoder.layer.5.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,321 INFO] tail_bert.encoder.layer.5.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,321 INFO] tail_bert.encoder.layer.5.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,321 INFO] tail_bert.encoder.layer.5.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,321 INFO] tail_bert.encoder.layer.5.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,321 INFO] tail_bert.encoder.layer.5.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,321 INFO] tail_bert.encoder.layer.5.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,322 INFO] tail_bert.encoder.layer.5.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,322 INFO] tail_bert.encoder.layer.5.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,322 INFO] tail_bert.encoder.layer.5.output.dense.bias: 768\n","[2022-05-26 18:40:29,322 INFO] tail_bert.encoder.layer.5.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,322 INFO] tail_bert.encoder.layer.5.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,322 INFO] tail_bert.encoder.layer.6.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,322 INFO] tail_bert.encoder.layer.6.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,322 INFO] tail_bert.encoder.layer.6.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.output.dense.bias: 768\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.6.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,323 INFO] tail_bert.encoder.layer.7.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.output.dense.bias: 768\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,324 INFO] tail_bert.encoder.layer.7.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.output.dense.bias: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,325 INFO] tail_bert.encoder.layer.8.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.output.dense.bias: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,326 INFO] tail_bert.encoder.layer.9.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,327 INFO] tail_bert.encoder.layer.10.output.dense.bias: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.10.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.10.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.self.query.weight: 589824\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.self.query.bias: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.self.key.weight: 589824\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.self.key.bias: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.self.value.weight: 589824\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.self.value.bias: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.output.dense.weight: 589824\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.output.dense.bias: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.attention.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,328 INFO] tail_bert.encoder.layer.11.intermediate.dense.weight: 2359296\n","[2022-05-26 18:40:29,329 INFO] tail_bert.encoder.layer.11.intermediate.dense.bias: 3072\n","[2022-05-26 18:40:29,329 INFO] tail_bert.encoder.layer.11.output.dense.weight: 2359296\n","[2022-05-26 18:40:29,329 INFO] tail_bert.encoder.layer.11.output.dense.bias: 768\n","[2022-05-26 18:40:29,329 INFO] tail_bert.encoder.layer.11.output.LayerNorm.weight: 768\n","[2022-05-26 18:40:29,329 INFO] tail_bert.encoder.layer.11.output.LayerNorm.bias: 768\n","[2022-05-26 18:40:29,329 INFO] tail_bert.pooler.dense.weight: 589824\n","[2022-05-26 18:40:29,329 INFO] tail_bert.pooler.dense.bias: 768\n","[2022-05-26 18:40:29,329 INFO] Number of parameters: 218.0M\n","[2022-05-26 18:40:29,330 INFO] In test mode: False\n","[2022-05-26 18:40:29,840 INFO] Load 272115 examples from data/FB15k237/train.txt.json\n","[2022-05-26 18:40:33,568 INFO] In test mode: False\n","[2022-05-26 18:40:33,639 INFO] Load 17535 examples from data/FB15k237/valid.txt.json\n","[2022-05-26 18:40:33,759 INFO] Total training steps: 76532, warmup steps: 400\n","[2022-05-26 18:40:33,833 INFO] Args={\n","    \"pretrained_model\": \"bert-base-uncased\",\n","    \"task\": \"FB15k237\",\n","    \"train_path\": \"data/FB15k237/train.txt.json\",\n","    \"valid_path\": \"data/FB15k237/valid.txt.json\",\n","    \"commonsense_path\": \"data/FB15k237\",\n","    \"model_dir\": \"ouput\",\n","    \"warmup\": 400,\n","    \"max_to_keep\": 5,\n","    \"grad_clip\": 10.0,\n","    \"pooling\": \"mean\",\n","    \"dropout\": 0.1,\n","    \"use_amp\": true,\n","    \"t\": 0.05,\n","    \"use_link_graph\": true,\n","    \"eval_every_n_step\": 10000,\n","    \"pre_batch\": 2,\n","    \"pre_batch_weight\": 0.5,\n","    \"additive_margin\": 0.02,\n","    \"finetune_t\": true,\n","    \"max_num_tokens\": 50,\n","    \"cake_ratio\": 1.0,\n","    \"use_self_negative\": true,\n","    \"workers\": 4,\n","    \"epochs\": 18,\n","    \"batch_size\": 128,\n","    \"lr\": 1e-05,\n","    \"lr_scheduler\": \"linear\",\n","    \"weight_decay\": 0.0001,\n","    \"print_freq\": 20,\n","    \"seed\": null,\n","    \"is_test\": false,\n","    \"rerank_n_hop\": 2,\n","    \"neighbor_weight\": 0.0,\n","    \"eval_model_path\": \"\"\n","}\n","[2022-05-26 18:40:35,583 INFO] Load 14541 entities from data/FB15k237\\entities.json\n","[2022-05-26 18:40:35,584 INFO] Triplets path: ['data/FB15k237/train.txt.json']\n","[2022-05-26 18:40:37,540 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-26 18:40:37,541 INFO] Start to build link graph from data/FB15k237/train.txt.json\n","[2022-05-26 18:40:38,453 INFO] Done build link graph with 14505 nodes\n","2022-05-26 18:40:40.499092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-26 18:40:40.499515: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-26 18:40:45,032 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-26 18:40:45,032 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-26 18:40:50,433 INFO] Load 14541 entities from data/FB15k237\\entities.json\n","[2022-05-26 18:40:50,433 INFO] Triplets path: ['data/FB15k237/train.txt.json']\n","[2022-05-26 18:40:52,516 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-26 18:40:52,517 INFO] Start to build link graph from data/FB15k237/train.txt.json\n","[2022-05-26 18:40:53,476 INFO] Done build link graph with 14505 nodes\n","2022-05-26 18:40:55.543632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-26 18:40:55.544014: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-26 18:41:00,518 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-26 18:41:00,518 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-26 18:41:06,310 INFO] Load 14541 entities from data/FB15k237\\entities.json\n","[2022-05-26 18:41:06,310 INFO] Triplets path: ['data/FB15k237/train.txt.json']\n","[2022-05-26 18:41:08,209 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-26 18:41:08,210 INFO] Start to build link graph from data/FB15k237/train.txt.json\n","[2022-05-26 18:41:09,065 INFO] Done build link graph with 14505 nodes\n","2022-05-26 18:41:11.017337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-26 18:41:11.017776: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-26 18:41:15,203 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-26 18:41:15,203 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-26 18:41:21,075 INFO] Load 14541 entities from data/FB15k237\\entities.json\n","[2022-05-26 18:41:21,075 INFO] Triplets path: ['data/FB15k237/train.txt.json']\n","[2022-05-26 18:41:22,994 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-26 18:41:22,995 INFO] Start to build link graph from data/FB15k237/train.txt.json\n","[2022-05-26 18:41:23,855 INFO] Done build link graph with 14505 nodes\n","2022-05-26 18:41:25.821320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-26 18:41:25.821689: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-26 18:41:30,636 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-26 18:41:30,636 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-26 18:41:38,762 INFO] Build tokenizer from bert-base-uncased\n","[2022-05-26 18:41:38,829 INFO] Build tokenizer from bert-base-uncased\n","[2022-05-26 18:41:38,927 INFO] Build tokenizer from bert-base-uncased\n","[2022-05-26 18:41:39,002 INFO] Build tokenizer from bert-base-uncased\n","Traceback (most recent call last):\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3.5\\main.py\", line 30, in <module>\n","    main()\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3.5\\main.py\", line 25, in main\n","    trainer.train_loop()\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3.5\\trainer.py\", line 74, in train_loop\n","    self.train_epoch(epoch)\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3.5\\trainer.py\", line 149, in train_epoch\n","    outputs = self.model(**batch_dict)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3.5\\models.py\", line 66, in forward\n","    hr_vector = self._encode(self.hr_bert,\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3.5\\models.py\", line 47, in _encode\n","    outputs = encoder(input_ids=token_ids,\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 996, in forward\n","    encoder_outputs = self.encoder(\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 585, in forward\n","    layer_outputs = layer_module(\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 513, in forward\n","    layer_output = apply_chunking_to_forward(\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2472, in apply_chunking_to_forward\n","    return forward_fn(*input_tensors)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 525, in feed_forward_chunk\n","    intermediate_output = self.intermediate(attention_output)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 426, in forward\n","    hidden_states = self.dense(hidden_states)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 94, in forward\n","    return F.linear(input, self.weight, self.bias)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\", line 1753, in linear\n","    return torch._C._nn.linear(input, weight, bias)\n","RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`\n"]}],"source":["!python -u main.py \\\n","--model-dir \"ouput\" \\\n","--pretrained-model bert-base-uncased \\\n","--pooling mean \\\n","--lr 1e-5 \\\n","--use-link-graph \\\n","--train-path \"data/FB15k237/train.txt.json\" \\\n","--valid-path \"data/FB15k237/valid.txt.json\" \\\n","--commonsense-path \"data/FB15k237\" \\\n","--task FB15k237 \\\n","--batch-size 128 \\\n","--print-freq 20 \\\n","--additive-margin 0.02 \\\n","--use-amp \\\n","--use-self-negative \\\n","--finetune-t \\\n","--pre-batch 2 \\\n","--epochs 18 \\\n","--workers 4 \\\n","--cake-ratio 1 \\\n","--max-to-keep 5  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXt1r50dxLDf","outputId":"fbcd8f4b-2e5c-4b2c-85e1-ec4850648870"},"outputs":[{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3\\evaluate.py\", line 10, in <module>\n","    from config import args\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver3\\config.py\", line 96, in <module>\n","    assert os.path.exists(args.eval_model_path), 'One of args.model_dir and args.eval_model_path should be valid path'\n","AssertionError: One of args.model_dir and args.eval_model_path should be valid path\n"]}],"source":["!python -u evaluate.py \\\n","--task FB15k237 \\\n","--is-test \\\n","--eval-model-path \"ouput/model_best.mdl\" \\\n","--neighbor-weight 0.05 \\\n","--rerank-n-hop 2 \\\n","--train-path \"data/FB15k237/train.txt.json\" \\\n","--valid-path \"data/FB15k237/test.txt.json\" "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-FE8xIpT_iS"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CocaKE.ipynb","provenance":[]},"interpreter":{"hash":"91bb753b057673435fb8d6f6a083e6c818364728098c7ae050ca3a25357dd754"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
