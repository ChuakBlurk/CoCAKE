{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8236,"status":"ok","timestamp":1653378015397,"user":{"displayName":"Bruce HU","userId":"02309357718155453395"},"user_tz":-120},"id":"vZwq84Xtc1JK","outputId":"1dab5771-2d2b-4a69-9ea5-28dfa329f4c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 22.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 73.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55_w7Exe2Mj5","outputId":"605a055b-a888-4679-9434-53305236a62b"},"outputs":[{"name":"stderr","output_type":"stream","text":["[2022-05-24 13:45:17,587 INFO] Load 14541 entities from CocaKE_ver2/data/FB15k237\\entities.json\n","[2022-05-24 13:45:17,587 INFO] Triplets path: ['CocaKE_ver2/data/FB15k237/train.txt.json']\n","[2022-05-24 13:45:18,989 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-24 13:45:18,989 INFO] Start to build link graph from CocaKE_ver2/data/FB15k237/train.txt.json\n","[2022-05-24 13:45:19,635 INFO] Done build link graph with 14505 nodes\n","2022-05-24 13:45:21.316664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-24 13:45:21.317110: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-24 13:45:25,131 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-24 13:45:25,131 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-24 13:45:29,705 INFO] Build tokenizer from bert-base-uncased\n","[2022-05-24 13:45:29,705 INFO] => creating model\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-05-24 13:45:32,195 INFO] CustomBertModel(\n","  (hr_bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (tail_bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n",")\n","e:\\Anaconda\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","[2022-05-24 13:45:35,222 INFO] log_inv_t: 1.0\n","[2022-05-24 13:45:35,222 INFO] hr_bert.embeddings.word_embeddings.weight: 23440896\n","[2022-05-24 13:45:35,222 INFO] hr_bert.embeddings.position_embeddings.weight: 393216\n","[2022-05-24 13:45:35,222 INFO] hr_bert.embeddings.token_type_embeddings.weight: 1536\n","[2022-05-24 13:45:35,222 INFO] hr_bert.embeddings.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,222 INFO] hr_bert.embeddings.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,222 INFO] hr_bert.encoder.layer.0.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,222 INFO] hr_bert.encoder.layer.0.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,222 INFO] hr_bert.encoder.layer.0.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,222 INFO] hr_bert.encoder.layer.0.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,222 INFO] hr_bert.encoder.layer.0.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.output.dense.bias: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.0.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.1.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.1.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.1.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.1.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.1.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.1.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,223 INFO] hr_bert.encoder.layer.1.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.output.dense.bias: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.1.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.2.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.2.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.2.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.2.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.2.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.2.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.2.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,224 INFO] hr_bert.encoder.layer.2.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.2.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.2.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.2.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.2.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.2.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.2.output.dense.bias: 768\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.2.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.2.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.3.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.3.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,225 INFO] hr_bert.encoder.layer.3.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.output.dense.bias: 768\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.3.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,226 INFO] hr_bert.encoder.layer.4.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,227 INFO] hr_bert.encoder.layer.4.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.4.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.4.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.4.output.dense.bias: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.4.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.4.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,228 INFO] hr_bert.encoder.layer.5.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.5.output.dense.bias: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.5.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.5.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.output.dense.bias: 768\n","[2022-05-24 13:45:35,229 INFO] hr_bert.encoder.layer.6.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.6.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.output.dense.bias: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.7.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,230 INFO] hr_bert.encoder.layer.8.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.output.dense.bias: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.8.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,231 INFO] hr_bert.encoder.layer.9.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.output.dense.bias: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.9.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.10.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.10.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,232 INFO] hr_bert.encoder.layer.10.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.output.dense.bias: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.10.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.11.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.11.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.11.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.11.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.11.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,233 INFO] hr_bert.encoder.layer.11.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.output.dense.bias: 768\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,234 INFO] hr_bert.encoder.layer.11.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,234 INFO] hr_bert.pooler.dense.weight: 589824\n","[2022-05-24 13:45:35,234 INFO] hr_bert.pooler.dense.bias: 768\n","[2022-05-24 13:45:35,234 INFO] tail_bert.embeddings.word_embeddings.weight: 23440896\n","[2022-05-24 13:45:35,234 INFO] tail_bert.embeddings.position_embeddings.weight: 393216\n","[2022-05-24 13:45:35,234 INFO] tail_bert.embeddings.token_type_embeddings.weight: 1536\n","[2022-05-24 13:45:35,234 INFO] tail_bert.embeddings.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,234 INFO] tail_bert.embeddings.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,234 INFO] tail_bert.encoder.layer.0.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.output.dense.bias: 768\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,235 INFO] tail_bert.encoder.layer.0.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.output.dense.bias: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.1.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.2.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,236 INFO] tail_bert.encoder.layer.2.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.output.dense.bias: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.2.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.3.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.3.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.3.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,237 INFO] tail_bert.encoder.layer.3.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.output.dense.bias: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.3.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.4.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.4.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.4.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.4.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,238 INFO] tail_bert.encoder.layer.4.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.output.dense.bias: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.4.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.5.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.5.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.5.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.5.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,239 INFO] tail_bert.encoder.layer.5.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.output.dense.bias: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.5.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.6.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.6.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.6.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.6.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.6.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.6.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,240 INFO] tail_bert.encoder.layer.6.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.output.dense.bias: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.6.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.7.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.7.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.7.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.7.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.7.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.7.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.7.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,241 INFO] tail_bert.encoder.layer.7.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.7.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.7.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.7.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.7.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.7.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.7.output.dense.bias: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.7.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.7.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,242 INFO] tail_bert.encoder.layer.8.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.8.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.8.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.8.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.8.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.8.output.dense.bias: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.8.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.8.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,243 INFO] tail_bert.encoder.layer.9.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.9.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.9.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.9.output.dense.bias: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.9.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.9.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,244 INFO] tail_bert.encoder.layer.10.output.dense.bias: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.10.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.10.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.self.query.weight: 589824\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.self.query.bias: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.self.key.weight: 589824\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.self.key.bias: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.self.value.weight: 589824\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.self.value.bias: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.output.dense.bias: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:35,245 INFO] tail_bert.encoder.layer.11.output.dense.weight: 2359296\n","[2022-05-24 13:45:35,246 INFO] tail_bert.encoder.layer.11.output.dense.bias: 768\n","[2022-05-24 13:45:35,246 INFO] tail_bert.encoder.layer.11.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:35,246 INFO] tail_bert.encoder.layer.11.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:35,246 INFO] tail_bert.pooler.dense.weight: 589824\n","[2022-05-24 13:45:35,246 INFO] tail_bert.pooler.dense.bias: 768\n","[2022-05-24 13:45:35,246 INFO] Number of parameters: 218.0M\n","[2022-05-24 13:45:35,272 INFO] In test mode: False\n","[2022-05-24 13:45:35,684 INFO] Load 272115 examples from CocaKE_ver2/data/FB15k237/train.txt.json\n","[2022-05-24 13:45:38,696 INFO] In test mode: False\n","[2022-05-24 13:45:38,739 INFO] Load 17535 examples from CocaKE_ver2/data/FB15k237/valid.txt.json\n","[2022-05-24 13:45:39,131 INFO] Total training steps: 332, warmup steps: 33\n","[2022-05-24 13:45:39,131 INFO] Use 1 gpus for training\n","[2022-05-24 13:45:39,132 INFO] => creating model\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-05-24 13:45:41,345 INFO] CustomBertModel(\n","  (hr_bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (tail_bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n",")\n","[2022-05-24 13:45:41,621 INFO] log_inv_t: 1.0\n","[2022-05-24 13:45:41,621 INFO] hr_bert.embeddings.word_embeddings.weight: 23440896\n","[2022-05-24 13:45:41,621 INFO] hr_bert.embeddings.position_embeddings.weight: 393216\n","[2022-05-24 13:45:41,621 INFO] hr_bert.embeddings.token_type_embeddings.weight: 1536\n","[2022-05-24 13:45:41,622 INFO] hr_bert.embeddings.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,622 INFO] hr_bert.embeddings.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,622 INFO] hr_bert.encoder.layer.0.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.0.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.0.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.0.output.dense.bias: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.0.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.0.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,623 INFO] hr_bert.encoder.layer.1.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.1.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.1.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.1.output.dense.bias: 768\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.1.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.1.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,624 INFO] hr_bert.encoder.layer.2.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.2.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.2.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.2.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.2.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.2.output.dense.bias: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.2.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.2.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,625 INFO] hr_bert.encoder.layer.3.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.3.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.3.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.3.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.3.output.dense.bias: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.3.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.3.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,626 INFO] hr_bert.encoder.layer.4.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.4.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.4.output.dense.bias: 768\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.4.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.4.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.5.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.5.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.5.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.5.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.5.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.5.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.5.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,627 INFO] hr_bert.encoder.layer.5.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.5.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.5.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.5.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.5.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.5.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.5.output.dense.bias: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.5.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.5.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,628 INFO] hr_bert.encoder.layer.6.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.6.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.6.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.6.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.6.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.6.output.dense.bias: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.6.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.6.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,629 INFO] hr_bert.encoder.layer.7.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.7.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.7.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.7.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.7.output.dense.bias: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.7.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.7.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,630 INFO] hr_bert.encoder.layer.8.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.8.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.8.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.8.output.dense.bias: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.8.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.8.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,631 INFO] hr_bert.encoder.layer.9.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.9.output.dense.bias: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.9.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.9.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.output.dense.bias: 768\n","[2022-05-24 13:45:41,632 INFO] hr_bert.encoder.layer.10.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.10.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.output.dense.bias: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.encoder.layer.11.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,633 INFO] hr_bert.pooler.dense.weight: 589824\n","[2022-05-24 13:45:41,634 INFO] hr_bert.pooler.dense.bias: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.embeddings.word_embeddings.weight: 23440896\n","[2022-05-24 13:45:41,634 INFO] tail_bert.embeddings.position_embeddings.weight: 393216\n","[2022-05-24 13:45:41,634 INFO] tail_bert.embeddings.token_type_embeddings.weight: 1536\n","[2022-05-24 13:45:41,634 INFO] tail_bert.embeddings.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.embeddings.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,634 INFO] tail_bert.encoder.layer.0.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.0.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.0.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.0.output.dense.bias: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.0.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.0.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,635 INFO] tail_bert.encoder.layer.1.output.dense.bias: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.1.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.1.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.output.dense.bias: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,636 INFO] tail_bert.encoder.layer.2.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.output.dense.bias: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,637 INFO] tail_bert.encoder.layer.3.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.output.dense.bias: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,638 INFO] tail_bert.encoder.layer.4.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.output.dense.bias: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.5.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,639 INFO] tail_bert.encoder.layer.6.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.output.dense.bias: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.6.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,640 INFO] tail_bert.encoder.layer.7.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.output.dense.bias: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.7.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.8.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.8.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,641 INFO] tail_bert.encoder.layer.8.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.output.dense.bias: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.8.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.9.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.9.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.9.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.9.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,642 INFO] tail_bert.encoder.layer.9.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.output.dense.bias: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.9.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.10.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.10.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.10.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.10.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.10.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.10.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,643 INFO] tail_bert.encoder.layer.10.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.output.dense.bias: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.10.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.11.attention.self.query.weight: 589824\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.11.attention.self.query.bias: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.11.attention.self.key.weight: 589824\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.11.attention.self.key.bias: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.11.attention.self.value.weight: 589824\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.11.attention.self.value.bias: 768\n","[2022-05-24 13:45:41,644 INFO] tail_bert.encoder.layer.11.attention.output.dense.weight: 589824\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.attention.output.dense.bias: 768\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.attention.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.attention.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.intermediate.dense.weight: 2359296\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.intermediate.dense.bias: 3072\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.output.dense.weight: 2359296\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.output.dense.bias: 768\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.output.LayerNorm.weight: 768\n","[2022-05-24 13:45:41,645 INFO] tail_bert.encoder.layer.11.output.LayerNorm.bias: 768\n","[2022-05-24 13:45:41,645 INFO] tail_bert.pooler.dense.weight: 589824\n","[2022-05-24 13:45:41,645 INFO] tail_bert.pooler.dense.bias: 768\n","[2022-05-24 13:45:41,645 INFO] Number of parameters: 218.0M\n","[2022-05-24 13:45:41,702 INFO] In test mode: False\n","[2022-05-24 13:45:42,104 INFO] Load 272115 examples from CocaKE_ver2/data/FB15k237/train.txt.json\n","[2022-05-24 13:45:45,403 INFO] In test mode: False\n","[2022-05-24 13:45:45,434 INFO] Load 17535 examples from CocaKE_ver2/data/FB15k237/valid.txt.json\n","[2022-05-24 13:45:45,472 INFO] Total training steps: 332, warmup steps: 33\n","[2022-05-24 13:45:45,472 INFO] Args={\n","    \"pretrained_model\": \"bert-base-uncased\",\n","    \"task\": \"FB15k237\",\n","    \"train_path\": \"CocaKE_ver2/data/FB15k237/train.txt.json\",\n","    \"valid_path\": \"CocaKE_ver2/data/FB15k237/valid.txt.json\",\n","    \"commonsense_path\": \"CocaKE_ver2/data/FB15k237\",\n","    \"model_dir\": \"ouput\",\n","    \"warmup\": 33,\n","    \"max_to_keep\": 5,\n","    \"grad_clip\": 10.0,\n","    \"pooling\": \"mean\",\n","    \"dropout\": 0.1,\n","    \"use_amp\": true,\n","    \"t\": 0.05,\n","    \"use_link_graph\": true,\n","    \"eval_every_n_step\": 10000,\n","    \"pre_batch\": 2,\n","    \"cake_ratio\": 0.5,\n","    \"pre_batch_weight\": 0.5,\n","    \"additive_margin\": 0.02,\n","    \"finetune_t\": true,\n","    \"max_num_tokens\": 50,\n","    \"use_self_negative\": true,\n","    \"workers\": 4,\n","    \"epochs\": 10,\n","    \"batch_size\": 128,\n","    \"lr\": 1e-05,\n","    \"lr_scheduler\": \"linear\",\n","    \"weight_decay\": 0.0001,\n","    \"print_freq\": 20,\n","    \"seed\": null,\n","    \"is_test\": false,\n","    \"rerank_n_hop\": 2,\n","    \"neighbor_weight\": 0.0,\n","    \"eval_model_path\": \"\"\n","}\n","[2022-05-24 13:45:46,760 INFO] Load 14541 entities from CocaKE_ver2/data/FB15k237\\entities.json\n","[2022-05-24 13:45:46,760 INFO] Triplets path: ['CocaKE_ver2/data/FB15k237/train.txt.json']\n","[2022-05-24 13:45:48,032 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-24 13:45:48,033 INFO] Start to build link graph from CocaKE_ver2/data/FB15k237/train.txt.json\n","[2022-05-24 13:45:48,641 INFO] Done build link graph with 14505 nodes\n","2022-05-24 13:45:50.112489: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-24 13:45:50.112732: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-24 13:45:53,345 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-24 13:45:53,345 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-24 13:45:57,224 INFO] Load 14541 entities from CocaKE_ver2/data/FB15k237\\entities.json\n","[2022-05-24 13:45:57,224 INFO] Triplets path: ['CocaKE_ver2/data/FB15k237/train.txt.json']\n","[2022-05-24 13:45:58,520 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-24 13:45:58,521 INFO] Start to build link graph from CocaKE_ver2/data/FB15k237/train.txt.json\n","[2022-05-24 13:45:59,115 INFO] Done build link graph with 14505 nodes\n","2022-05-24 13:46:00.585440: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-24 13:46:00.585984: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-24 13:46:03,810 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-24 13:46:03,810 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-24 13:46:07,702 INFO] Load 14541 entities from CocaKE_ver2/data/FB15k237\\entities.json\n","[2022-05-24 13:46:07,702 INFO] Triplets path: ['CocaKE_ver2/data/FB15k237/train.txt.json']\n","[2022-05-24 13:46:08,977 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-24 13:46:08,978 INFO] Start to build link graph from CocaKE_ver2/data/FB15k237/train.txt.json\n","[2022-05-24 13:46:09,564 INFO] Done build link graph with 14505 nodes\n","2022-05-24 13:46:11.044132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-24 13:46:11.044399: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-24 13:46:14,246 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-24 13:46:14,246 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-24 13:46:18,201 INFO] Load 14541 entities from CocaKE_ver2/data/FB15k237\\entities.json\n","[2022-05-24 13:46:18,201 INFO] Triplets path: ['CocaKE_ver2/data/FB15k237/train.txt.json']\n","[2022-05-24 13:46:19,532 INFO] Triplet statistics: 474 relations, 544230 triplets\n","[2022-05-24 13:46:19,533 INFO] Start to build link graph from CocaKE_ver2/data/FB15k237/train.txt.json\n","[2022-05-24 13:46:20,150 INFO] Done build link graph with 14505 nodes\n","2022-05-24 13:46:21.634079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-05-24 13:46:21.634440: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","[2022-05-24 13:46:24,879 INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","[2022-05-24 13:46:24,879 INFO] NumExpr defaulting to 8 threads.\n","[2022-05-24 13:46:31,649 INFO] Build tokenizer from bert-base-uncased\n","[2022-05-24 13:46:31,649 INFO] Build tokenizer from bert-base-uncased\n","[2022-05-24 13:46:31,658 INFO] Build tokenizer from bert-base-uncased\n","[2022-05-24 13:46:31,915 INFO] Build tokenizer from bert-base-uncased\n","Traceback (most recent call last):\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver2\\main.py\", line 26, in <module>\n","    main()\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver2\\main.py\", line 20, in main\n","    trainer.train_loop()\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver2\\trainer.py\", line 76, in train_loop\n","    self.train_epoch(epoch)\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver2\\trainer.py\", line 151, in train_epoch\n","    outputs = self.model(**batch_dict)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver2\\models.py\", line 66, in forward\n","    hr_vector = self._encode(self.hr_bert,\n","  File \"e:\\University\\Year 3 Spring\\Exchange\\ETH\\Lectures\\Computational Semantics\\Project\\CocaKE_Bruce\\CocaKE_ver2\\models.py\", line 47, in _encode\n","    outputs = encoder(input_ids=token_ids,\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 996, in forward\n","    encoder_outputs = self.encoder(\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 585, in forward\n","    layer_outputs = layer_module(\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 513, in forward\n","    layer_output = apply_chunking_to_forward(\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2472, in apply_chunking_to_forward\n","    return forward_fn(*input_tensors)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 525, in feed_forward_chunk\n","    intermediate_output = self.intermediate(attention_output)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 426, in forward\n","    hidden_states = self.dense(hidden_states)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 94, in forward\n","    return F.linear(input, self.weight, self.bias)\n","  File \"e:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\", line 1753, in linear\n","    return torch._C._nn.linear(input, weight, bias)\n","RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`\n"]}],"source":["!python -u CocaKE_ver2/main.py \\\n","--model-dir \"ouput\" \\\n","--pretrained-model bert-base-uncased \\\n","--pooling mean \\\n","--lr 1e-5 \\\n","--use-link-graph \\\n","--train-path \"CocaKE_ver2/data/FB15k237/train.txt.json\" \\\n","--valid-path \"CocaKE_ver2/data/FB15k237/valid.txt.json\" \\\n","--commonsense \"CocaKE_ver2/data/FB15k237\" \\\n","--task FB15k237 \\\n","--batch-size 128 \\\n","--print-freq 20 \\\n","--additive-margin 0.02 \\\n","--use-amp \\\n","--use-self-negative \\\n","--finetune-t \\\n","--pre-batch 2 \\\n","--epochs 10 \\\n","--workers 4 \\\n","--cake-ratio 0.5 \\\n","--max-to-keep 5 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1652736004094,"user":{"displayName":"Bruce HU","userId":"02309357718155453395"},"user_tz":-120},"id":"fsHAPIyscjw_","outputId":"4bd64e57-cb84-4f99-c0be-95e94e4e4d00"},"outputs":[{"name":"stdout","output_type":"stream","text":["python3: can't open file 'drive/MyDrive/CocaKE/CAKE/codes/run_cake.py': [Errno 2] No such file or directory\n"]}],"source":["!python -u CocaKE_ver3/main.py \\\n","--model-dir \"ouput\" \\\n","--pretrained-model bert-base-uncased \\\n","--pooling mean \\\n","--lr 1e-5 \\\n","--use-link-graph \\\n","--train-path \"CocaKE_ver3/data/FB15k237/train.txt.json\" \\\n","--valid-path \"CocaKE_ver3/data/FB15k237/valid.txt.json\" \\\n","--commonsense \"CocaKE_ver3/data/FB15k237\" \\\n","--task FB15k237 \\\n","--batch-size 128 \\\n","--print-freq 20 \\\n","--additive-margin 0.02 \\\n","--use-amp \\\n","--use-self-negative \\\n","--finetune-t \\\n","--pre-batch 2 \\\n","--epochs 10 \\\n","--workers 4 \\\n","--cake-ratio 0.5 \\\n","--max-to-keep 5 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-FE8xIpT_iS"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CocaKE.ipynb","provenance":[]},"interpreter":{"hash":"91bb753b057673435fb8d6f6a083e6c818364728098c7ae050ca3a25357dd754"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
